# TASK3-Neural-Style-Transfer
COMPANY: CODETECH IT SOLUTIONS

NAME: AKULA VAISHNAVI

INTERNID: CODF288

DOMAIN: ARTIFICIAL INTELLIGENCE

DURATION: 4 WEEKS

MENTOR: NEELA SANTHOSH KUMAR

DESCRIPTION: This Jupyter Notebook presents a complete implementation of neural style transfer, a technique that merges the content of one image with the artistic style of another, resulting in a new image that retains the structure of the original while adopting the texture and appearance of the style image. The notebook uses TensorFlow and TensorFlow Hub, particularly leveraging a pre-trained model from TensorFlow Hub called magenta/arbitrary-image-stylization-v1-256, which allows the application of arbitrary styles to content images with minimal configuration. The process begins with installing and importing necessary libraries such as tensorflow, tensorflow_hub, numpy, cv2, matplotlib, and Pillow, setting the stage for image loading, processing, and visualization. It then defines utility functions to read and preprocess input images. These images include a content image (e.g., a photo of Spider-Man) and a style image (e.g., a painting or sky image), both of which are loaded using TensorFlow utilities and converted into the required tensor format. The style transfer model is then loaded directly from TensorFlow Hub, demonstrating how simple it is to use high-quality pre-trained models from the cloud. This model expects two images: a content image and a style image, both scaled and normalized properly to fit the model's requirements. Once the input preparation is complete, the style transfer model is applied. The model blends the features of both images to produce a stylized output, which is displayed using Matplotlib for visual comparison alongside the original inputs. Internally, the model uses convolutional neural networks (CNNs) to extract deep features from both content and style images and combines them by minimizing a loss function that balances content reconstruction with style imitation. This notebook not only simplifies a sophisticated deep learning concept but also offers flexibility in choosing arbitrary styles and content, making it ideal for both educational demonstrations and artistic experimentation. Additionally, the code includes support for file path manipulation and custom image loading functions that ensure compatibility with different environments and image types. The result is an elegant pipeline where users can plug in any pair of content and style images to generate creative results without writing complex neural network code from scratch. The notebook reflects how modern machine learning frameworks democratize access to artistic AI tools, enabling even those with limited deep learning knowledge to experiment with cutting-edge computer vision applications. Furthermore, it illustrates the power of transfer learning by utilizing models trained on extensive datasets and making them readily accessible through cloud-based hubs. As such, this notebook serves as a powerful demonstration of how machine learning can intersect with creativity, allowing developers, artists, and hobbyists to explore the fusion of art and technology. From a technical standpoint, it showcases best practices in model integration, image preprocessing, and result visualization, while from a user perspective, it provides an enjoyable and intuitive way to produce aesthetically pleasing images. Overall, the neural style transfer notebook is a clear, efficient, and interactive example of how deep learning can be used for creative expression through visual transformation.
